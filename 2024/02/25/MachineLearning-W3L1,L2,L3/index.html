<!DOCTYPE html><html lang="zh-cmn-Hans" prefix="og: http://ogp.me/ns#" class="han-init"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" /><title>MachineLearning｜ Notes2 &mdash; Xinyi He</title><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/vendor/primer-css/css/primer.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/components/collection.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/components/repo-card.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/sections/repo-list.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/components/boxed-group.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/globals/common.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/globals/responsive.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/posts/index.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/vendor/octicons/octicons/octicons.css"><link rel="stylesheet" href="https://mazhuang.org/rouge-themes/dist/github.css"><link rel="canonical" href="https://buliangzhang24.github.io/2024/02/25/MachineLearning-W3L1,L2,L3/"><link rel="alternate" type="application/atom+xml" title="Xinyi He" href="https://buliangzhang24.github.io/feed.xml"><link rel="shortcut icon" href="https://buliangzhang24.github.io/favicon.ico"><meta property="og:title" content="MachineLearning｜ Notes2"><meta name="keywords" content="Notes"><meta name="og:keywords" content="Notes"><meta name="description" content="W3L1 Unsupervised learningLabPCA Scaling pca_loadings»&gt;pca_fit.components_.T principal component scores»&gt; pca = PCA(random_state=42) pca_df = pd.DataFrame(pca.fit_transform(X_scaled)) PVE Clustering–Hierarchical Clustering hc_avg = linkage(X, method='average')hc_complete = linkage(X, method='complete')hc_single = linkage(X, method='single')dend = dendrogram(hc_avg)cut_tree(hc_avg, 2).ravel()就是只聚类了两个类型 Correlation-based distance can be by passing the method='correlation' argument to the linkage function. 如果我们有一个包含至少三个特征的数据集，我们可以计算两个数据点之间的相关性，并将其视为一种距离度量。具体来说，我们可以使用 Pearson 相关系数来计算相关性。Pearson 相关系数可以度量两个变量之间的线性关系程度 Applied PCA 获得Proportion Variance Explained(PVE)pca.explained_variance_ratio_ 手动算PVE，不用上面的代码![[a231610ce8f6af47eafbf207cd98180.png]]用这个公式，写这个Loop![[2421ca477df65ec16149569ec3aaecd.png]] hierarchical clustering 用complete linkage : hc_complete = linkage(USArrests, method ='complete') 改3个聚类还是4个聚类 缩放scaling 画 dendrogramscaler = StandardScaler()X_scaled = scaler.fit_transform(USArrests)hc_complete_sc = linkage(X_scaled, method ='complete')cut_tree(hc_complete_sc, 4).ravel() "><meta name="og:description" content="W3L1 Unsupervised learningLabPCA Scaling pca_loadings»&gt;pca_fit.components_.T principal component scores»&gt; pca = PCA(random_state=42) pca_df = pd.DataFrame(pca.fit_transform(X_scaled)) PVE Clustering–Hierarchical Clustering hc_avg = linkage(X, method='average')hc_complete = linkage(X, method='complete')hc_single = linkage(X, method='single')dend = dendrogram(hc_avg)cut_tree(hc_avg, 2).ravel()就是只聚类了两个类型 Correlation-based distance can be by passing the method='correlation' argument to the linkage function. 如果我们有一个包含至少三个特征的数据集，我们可以计算两个数据点之间的相关性，并将其视为一种距离度量。具体来说，我们可以使用 Pearson 相关系数来计算相关性。Pearson 相关系数可以度量两个变量之间的线性关系程度 Applied PCA 获得Proportion Variance Explained(PVE)pca.explained_variance_ratio_ 手动算PVE，不用上面的代码![[a231610ce8f6af47eafbf207cd98180.png]]用这个公式，写这个Loop![[2421ca477df65ec16149569ec3aaecd.png]] hierarchical clustering 用complete linkage : hc_complete = linkage(USArrests, method ='complete') 改3个聚类还是4个聚类 缩放scaling 画 dendrogramscaler = StandardScaler()X_scaled = scaler.fit_transform(USArrests)hc_complete_sc = linkage(X_scaled, method ='complete')cut_tree(hc_complete_sc, 4).ravel() "><meta property="og:url" content="https://buliangzhang24.github.io/2024/02/25/MachineLearning-W3L1,L2,L3/"><meta property="og:site_name" content="Xinyi He"><meta property="og:type" content="article"><meta property="og:locale" content="zh_CN" /><meta property="article:published_time" content="2024-02-25"> <script src="https://buliangzhang24.github.io/assets/vendor/jquery/dist/jquery.min.js"></script> <script src="https://buliangzhang24.github.io/assets/js/main.js"></script></head><body class="" data-mz=""><header class="site-header"><div class="container"><h1><a href="https://buliangzhang24.github.io/" title="Xinyi He"><span class="octicon octicon-mark-github"></span> Xinyi He</a></h1><button class="collapsed mobile-visible" type="button" onclick="toggleMenu();"> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button><nav class="site-header-nav" role="navigation"> <a href="https://buliangzhang24.github.io/" class="site-header-nav-item" target="" title="Home">Home</a> <a href="https://buliangzhang24.github.io/categories/" class="site-header-nav-item" target="" title="Categories">Categories</a> <a href="https://buliangzhang24.github.io/archives/" class="mobile-hidden site-header-nav-item" target="" title="Archives">Archives</a> <a href="https://buliangzhang24.github.io/fragments/" class="site-header-nav-item" target="" title="Fragments">Fragments</a> <a href="https://buliangzhang24.github.io/wiki/" class="site-header-nav-item" target="" title="Projects">Projects</a> <a href="https://buliangzhang24.github.io/links/" class="mobile-hidden site-header-nav-item" target="" title="Useful Links">Useful Links</a> <a href="https://buliangzhang24.github.io/about/" class="site-header-nav-item" target="" title="About">About</a> <a class="mobile-hidden" href="https://buliangzhang24.github.io/feed.xml"><span class="octicon octicon-rss" style="color:orange;"></span></a></nav></div></header><section class="collection-head small geopattern" data-pattern-id="MachineLearning"><div class="container"><div class="columns"><div class="column three-fourths"><div class="collection-title"><h1 class="collection-header">MachineLearning｜ Notes2</h1><div class="collection-info"> <span class="meta-info"> <span class="octicon octicon-calendar"></span> 2024/02/25 </span> <span class="meta-info"> <span class="octicon octicon-file-directory"></span> <a href="https://buliangzhang24.github.io/categories/#MachineLearning" title="MachineLearning">MachineLearning</a> </span> <span class="meta-info"> <span class="octicon octicon-clock"></span> 共 3950 字，约 12 分钟 </span></div></div></div><div class="column one-fourth mobile-hidden"><div class="collection-title"></div></div></div></div></section><section class="container content"><div class="columns"><div class="column three-fourths" ><article class="article-content markdown-body"><h1 id="w3l1-unsupervised-learning">W3L1 Unsupervised learning</h1><h2 id="lab">Lab</h2><h3 id="pca">PCA</h3><ul><li>Scaling</li><li>pca_loadings»&gt;pca_fit.components_.T</li><li>principal component scores»&gt; <code class="language-plaintext highlighter-rouge">pca = PCA(random_state=42)</code> <code class="language-plaintext highlighter-rouge">pca_df = pd.DataFrame(pca.fit_transform(X_scaled))</code></li><li>PVE<h3 id="clusteringhierarchical-clustering">Clustering–Hierarchical Clustering</h3><p><code class="language-plaintext highlighter-rouge">hc_avg = linkage(X, method='average')</code> <code class="language-plaintext highlighter-rouge">hc_complete = linkage(X, method='complete')</code> <code class="language-plaintext highlighter-rouge">hc_single = linkage(X, method='single')</code> <code class="language-plaintext highlighter-rouge">dend = dendrogram(hc_avg)</code> <code class="language-plaintext highlighter-rouge">cut_tree(hc_avg, 2).ravel()</code>就是只聚类了两个类型</p></li><li>Correlation-based distance can be by passing the <code class="language-plaintext highlighter-rouge">method='correlation'</code> argument to the linkage function. 如果我们有一个包含至少三个特征的数据集，我们可以计算两个数据点之间的相关性，并将其视为一种距离度量。具体来说，我们可以使用 Pearson 相关系数来计算相关性。Pearson 相关系数可以度量两个变量之间的线性关系程度<h2 id="applied">Applied</h2><h3 id="pca-1">PCA</h3><ol><li>获得Proportion Variance Explained(PVE)<code class="language-plaintext highlighter-rouge">pca.explained_variance_ratio_</code></li><li>手动算PVE，不用上面的代码![[a231610ce8f6af47eafbf207cd98180.png]]用这个公式，写这个Loop ![[2421ca477df65ec16149569ec3aaecd.png]]<h3 id="hierarchical-clustering">hierarchical clustering</h3></li><li>用complete linkage : <code class="language-plaintext highlighter-rouge">hc_complete = linkage(USArrests, method ='complete')</code></li><li>改3个聚类还是4个聚类</li><li>缩放scaling</li><li>画 dendrogram <code class="language-plaintext highlighter-rouge">scaler = StandardScaler()</code> <code class="language-plaintext highlighter-rouge">X_scaled = scaler.fit_transform(USArrests)</code> <code class="language-plaintext highlighter-rouge">hc_complete_sc = linkage(X_scaled, method ='complete')</code> <code class="language-plaintext highlighter-rouge">cut_tree(hc_complete_sc, 4).ravel()</code></li></ol></li></ul><p><code class="language-plaintext highlighter-rouge">dend = dendrogram(hc_complete_sc)</code></p><h3 id="在实际的数据上实践">在实际的数据上实践</h3><h1 id="w3l2-gaussian-mixture-models">W3L2 Gaussian Mixture Models</h1><h2 id="lab-1">Lab</h2><h3 id="k-means-clustering">K-means Clustering</h3><p><code class="language-plaintext highlighter-rouge">cls = KMeans(n_clusters=2, n_init=20)</code> <code class="language-plaintext highlighter-rouge">cls.fit(X) </code>clusters = cls.predict(X)<code class="language-plaintext highlighter-rouge"> K=2 进行聚类，并进行 20 次初始化(这个初始化就是随机选择选20次)，最后KMeans值报告最佳的值 </code>center = clustering.cluster_centers`得到total within-cluster sum of squares 改变cluster的数量也可以改变簇内平方和</p><h3 id="mixtures-of-gaussians">Mixtures-of-Gaussians </h3><ul><li>这个只适合拟合有高斯分布那种感觉的数据</li><li>对数似然 ( ll ) 在每次迭代中的变化如何较小，以及最终估计参数如何与我们用于生成数据的参数接近但不相同。</li><li>n_components</li><li>init_params=’kmeans’ （默认值）首先执行 $K$-means 并使用该结果来初始化 EM 算法。一般来说，这会产生更稳定的结果。</li><li>尝试加入reg_covar = 1e-6会防止过拟合</li><li>covariance_type = ‘diag’/ ‘spherical’考虑到协方差矩阵的分布<h2 id="applied-1">Applied</h2><h3 id="pca-and-kmeans">PCA and Kmeans</h3><ol><li>生成数据集：三个类 各有20个Ob,和50个变量</li><li>对 60 个观测值执行 PCA 并绘制前两个主成分得分向量。 这个分量指的是pca.fit_transform(X)也就是pca_loading的转置</li><li>K-means (K=3,2,4)这个结果就是K=3，分的好（看散点图）</li><li>现在执行 K-means在前两个主成分得分向量上而不是在原始数据上使用 K=3 进行聚类: As the clusters are easily separable in 2D, the clusters are exactly equal to the classes and seem less dependent on initialization.</li><li>用StandardScaler()去scaling，但是在这个数据里是没有区别的<h3 id="mixtures-of-gaussians-1">Mixtures of Gaussians</h3></li><li>画个Hist图，看它的数据是不是Gaussian分布</li><li>模型加 mixing proportions: <code class="language-plaintext highlighter-rouge">gm = GaussianMiture(n_components=2, verbose=2, verbose_interval=1, tol=1e-6).fit(waiting) </code>print(“pi =”,gm.weights_)` pi = [0.30793897 0.69206103] 哪个分布更有可能生成任意一个数据点。在你的模型中，第一个分布的权重为0.69206103（约为69.2%），第二个分布的权重为0.30793897（约为30.8%）。</li><li>现在用 K=1,2,…5 分量拟合多个高斯混合模型，并将对数似然（拟合模型的属性lower_bound_ ）绘制为 K 的函数»对数似然随着 K 不断增加，因为与训练数据的拟合变得越来越好。然而，从 1 个组件到 2 个组件有明显的跳跃，这表明 2 个组件足以满足该数据</li><li>分了训练集和测试集之后再重复3»实际结果取决于数据的分割，但通常 K&gt;2 的测试集的对数似然会（略微）降低，这表明对于较高的 K 值，模型过度拟合训练数据</li><li>Repeat 以上的 steps, but now fitting 2D components to both features at once. What is the optimal number of components? ![[f2c611d951a031d56496b2aa9656cef.png]]<h1 id="w3l3-deep-learning">W3L3 Deep Learning</h1><h2 id="a-feed-forward-neural-network-with-a-single-hidden-layer">A feed-forward neural network with a single hidden layer</h2></li><li>创建model <code class="language-plaintext highlighter-rouge">mlp = Sequential([</code>                 <code class="language-plaintext highlighter-rouge">layers.Input(shape=X_train.shape[1]),</code> 输入                   <code class="language-plaintext highlighter-rouge">layers.Dense(units=64, activation='relu'),</code> 隐藏层                   <code class="language-plaintext highlighter-rouge">layers.Dropout(rate=0.2),</code> 用来validation的一个部分                   <code class="language-plaintext highlighter-rouge">layers.Dense(units=1, activation='linear'),</code> 输出层                 <code class="language-plaintext highlighter-rouge">])</code></li><li><code class="language-plaintext highlighter-rouge">mlp.summary()</code> ![[dbff07ecea1907a3e66853aeb1eb37a.png]]</li><li><code class="language-plaintext highlighter-rouge">mlp.compile(loss='mse', metrics=['mae', 'R2Score'], optimizer='rmsprop')</code></li><li>拟合 ![[041499102e32d795724abc43effcb0d.png]]</li><li>激活函数： ReLU是Rectified Linear Unit的缩写，是一种常用的激活函数，它将输入 x 转换为输出 y 的方法是： Sigmoid函数（也称为Logistic函数）：这是一种经典的激活函数，它将输入映射到一个范围为0到1之间的值。 Tanh函数（双曲正切函数）：这是另一种常用的激活函数，它将输入映射到一个范围为-1到1之间的值。<h3 id="解读这两个图">解读这两个图</h3><p>![[a7378953384726be6f13b50e2a127af.png]] ![[01409990404ad62244eb5b3b90a5a29.png]] 第一个图就是，在拐点的地方(elbow point)，就是150左右，之前是underfiting， 后面validation随着这个epoch的增大而Loss开始增大，就是overfiting。之前validation 都是随着epoch的增大而loss减小。然后training随着一直迭代，loss一直变小。 第二个图就是，在拐点的地方之后validation的R^2开始随着epoch下降，training的R^2开始随着epoch上升，就是过拟合，之前就是underfitting。</p><h3 id="比较linear-lasso和mlp">比较Linear, Lasso和MLP</h3></li></ol></li></ul><h2 id="the-mnist-dataset-with-the-mnist-dataset">The MNIST dataset with the MNIST dataset</h2><h2 id="convolutional-neural-networks-with-the-cifar-dataset">Convolutional Neural Networks with the CIFAR dataset</h2><p>![[e81762e5e90e50affc3cd56de26e519.png]] 这个CNN卷积，就是我每卷积一次，它就由一个图变成两个图，最后就是展直了，变成了一个数列一样的只有一列（一维向量）。将特征图展平为一维向量的主要原因之一是为了使得它们可以作为全连接层的输入，提高性能</p><ol><li><strong>卷积（Convolution）：</strong> 将滤波器与输入图像进行卷积运算，计算出滤波器与图像上每个局部区域的内积。这一步可以理解为提取出图像的局部特征。</li><li><strong>激活函数（Activation）：</strong> 将卷积后的结果通过激活函数进行非线性变换，从而增加网络的非线性特性。常用的激活函数有 ReLU、sigmoid、tanh 等。</li><li><strong>池化（Pooling）：</strong> 将卷积后的结果进行池化运算，从而降低特征图的维度，减少参数数量。常用的池化方式有最大池化（Max Pooling）和平均池化（Average Pooling）。</li></ol><div style="margin-top:2em;padding:0 1.5em;border:1px solid #d3d3d3;background-color:#deebf7"><h3>文档信息</h3><ul><li>本文作者：<a href="https://buliangzhang24.github.io" target="_blank">Xinyi He</a></li><li>本文链接：<a href="https://buliangzhang24.github.io/2024/02/25/MachineLearning-W3L1,L2,L3/" target="_blank">https://buliangzhang24.github.io/2024/02/25/MachineLearning-W3L1,L2,L3/</a></li><li>版权声明：自由转载-非商用-非衍生-保持署名（<a href="http://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank">创意共享3.0许可证</a>）</li></ul></div></article><div class="share"></div><div class="comment"> <script src="https://giscus.app/client.js" data-repo="Buliangzhang24/Buliangzhang24.github.io" data-repo-id="MDEwOlJlcG9zaXRvcnk5MzEyNzkxNw==" data-category="Announcements" data-category-id="DIC_kwDOBY0E7c4CRtg9" data-mapping="title" data-strict="1" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="zh-CN" data-loading="lazy" crossorigin="anonymous" async> </script></div></div><div class="column one-fourth"><h3>Search</h3><div id="site_search"> <input style="width:96%" type="text" id="search_box" placeholder="Search"></div><ul id="search_results" style="font-size:14px;list-style-type:none;padding-top:10px;padding-left:10px;"></ul><script src="https://buliangzhang24.github.io/assets/js/simple-jekyll-search.min.js"></script> <script type="text/javascript"> SimpleJekyllSearch({ searchInput: document.getElementById('search_box'), resultsContainer: document.getElementById('search_results'), json: 'https://buliangzhang24.github.io/assets/search_data.json?v=1727794843', searchResultTemplate: '<li><a href="{url}" title="{title}">{title}</a></li>', noResultsText: 'No results found', limit: 10, fuzzy: false, exclude: ['Welcome'] }) </script><h3 class="post-directory-title mobile-hidden">Table of Contents</h3><div id="post-directory-module" class="mobile-hidden"><section class="post-directory"><dl></dl></section></div><script src="https://buliangzhang24.github.io/assets/js/jquery.toc.js"></script></div></div></section><footer class="container"><div class="site-footer" role="contentinfo"><div class="copyright left mobile-block"> © 2024 <span title="Xinyi He">Xinyi He</span> <a href="javascript:window.scrollTo(0,0)" class="right mobile-visible">TOP</a></div><ul class="site-footer-links right mobile-hidden"><li> <a href="javascript:window.scrollTo(0,0)" >TOP</a></li></ul><a href="https://github.com/Buliangzhang24/Buliangzhang24.github.io" target="_blank" aria-label="view source code"> <span class="mega-octicon octicon-mark-github" title="GitHub"></span> </a><ul class="site-footer-links mobile-hidden"><li> <a href="https://buliangzhang24.github.io/" title="Home" target="">Home</a></li><li> <a href="https://buliangzhang24.github.io/categories/" title="Categories" target="">Categories</a></li><li> <a href="https://buliangzhang24.github.io/archives/" title="Archives" target="">Archives</a></li><li> <a href="https://buliangzhang24.github.io/fragments/" title="Fragments" target="">Fragments</a></li><li> <a href="https://buliangzhang24.github.io/wiki/" title="Projects" target="">Projects</a></li><li> <a href="https://buliangzhang24.github.io/links/" title="Useful Links" target="">Useful Links</a></li><li> <a href="https://buliangzhang24.github.io/about/" title="About" target="">About</a></li><li><a href="https://buliangzhang24.github.io/feed.xml"><span class="octicon octicon-rss" style="color:orange;"></span></a></li></ul></div></footer><div class="tools-wrapper"> <a class="gotop" href="#" title="回到顶部"><span class="octicon octicon-arrow-up"></span></a></div><script src="https://buliangzhang24.github.io/assets/js/geopattern.js"></script> <script> jQuery(document).ready(function($) { $('.geopattern').each(function(){ $(this).geopattern($(this).data('pattern-id')); }); /* hljs.initHighlightingOnLoad(); */ }); </script></body></html>
