<!DOCTYPE html><html lang="zh-cmn-Hans" prefix="og: http://ogp.me/ns#" class="han-init"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" /><title>MachineLearning｜ Notes1 &mdash; Xinyi He</title><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/vendor/primer-css/css/primer.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/components/collection.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/components/repo-card.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/sections/repo-list.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/components/boxed-group.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/globals/common.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/globals/responsive.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/posts/index.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/vendor/octicons/octicons/octicons.css"><link rel="stylesheet" href="https://mazhuang.org/rouge-themes/dist/github.css"><link rel="canonical" href="https://buliangzhang24.github.io/2024/02/25/MachineLearning-W2L1,-L2/"><link rel="alternate" type="application/atom+xml" title="Xinyi He" href="https://buliangzhang24.github.io/feed.xml"><link rel="shortcut icon" href="https://buliangzhang24.github.io/favicon.ico"><meta property="og:title" content="MachineLearning｜ Notes1"><meta name="keywords" content="Notes"><meta name="og:keywords" content="Notes"><meta name="description" content="Sampling Methods and Model Selection8 Cross-Validation 生成数据集 设置随机种子，然后计算使用最小二乘拟合以下四个模型（增加次数的一次到四次的多项式）所产生的 LOOCV 误差 使用最小二乘法拟合以上的每个模型所产生的系数估计值的统计显着性。这些结果与基于交叉验证结果得出的结论一致吗？ 得出的结论X1和X2的t统计值的绝对值是最大的， 所以对应了二次项 9. 直接计算数据集的std 和mean 通过Bootstrap来估计数据集的std 和mean def boot(var, n): m = np.zeros(n) for i in range(0, n): v    = var.sample(frac=1, replace=True) 就是百分之百，采样，有放回 m[i] = np.mean(v) res1 = np.mean(m) res2 = np.std(m) print('mu: %.5f; se: %.5f' %(res1, res2)) return(res1, res2) 调用： result = boot(medv, 1000) # close to (b) 置信区间 print('lowerbd:%.2f' %(result[0] - 2*result[1])) print('upperbd:%.2f' %(result[0] + 2*result[1])) from scipy import statsstats.t.interval(0.95,               # confidence level df = len(df)-1, # degrees of freedom loc = mu_hat,       # sample mean scale= mu_hat_se)   # sample std dev 中位数 中位数的标准误差 rovide an estimate for the tenth percentile of y # 6.9 生成模拟数据集np.random.randn(1) 是用来生成一个标准正态分布的随机数的。np.random.randn() 函数生成一个随机数，该随机数服从标准正态分布（均值为0，标准差为1） （1）10* 100 个 X， y是一个多项式 (2) 放到一个数据框里 执行这个两种model selection(1)best subset selectionlm = OLS(fit_intercept=True) lm_exhaustive = exhaustive_search(lm, X_new_df, y,nvmax=len(X_new_df.columns)) (2)forward and backwardlm = OLS(fit_intercept=True)lm_forward = forward_search(lm, X_new_df, y, nvmax=len(X_new_df.columns))lm = OLS(fit_intercept=True)lm_backward = backward_search(lm, X_new_df, y, nvmin=1) 现在将==套索模型==拟合到模拟数据，再次使用 X,X2,…,X10 作为预测变量。==使用交叉验证来选择 λ 的最佳值==。(这个其实是一整步，它是一起的)创建作为 ==λ 函数的交叉验证误差图==。（连这个是跟之前那一步一起的）报告所得的==系数估计值==，并讨论获得的结果。==(同时要scale 数据)== scale scaler = StandardScaler() X_new = scaler.fit_transform(X_new) 2. lambdas = 10 ** np.linspace(3,-3,50)生成1000到0.001的50个等间距的值 mean_scores = np.zeros(len(lambdas)) std_scores = np.zeros(len(lambdas)) for i, lambda_ in enumerate(lambdas): 它用于计算模型在交叉验证中的得分（我scoring设置什么它算什么，cv.mean就得到它的mean） cv = cross_val_score(Lasso(lambda_, max_iter=10000),X_new, y, cv=10, scoring='neg_mean_squared_error') mean_scores[i] = cv.mean() std_scores[i] = cv.std() 3.![[d26871bc8cfbf8b45cc98feed382a87.png]]就是yerr是标准差，lecture也提到了，以标准差作为一个间距 找个mean_scroe最小的一点mn，和对应的lambdas就是opt ![[1e233ecedc7b7977808dd41ae0a9776.png]]这个结果就是，coefficient 为0 的变量就不被考虑了4.现在根据模型 y=β0+β7X7+e 生成响应向量 y ，并执行最佳子集选择和套索。讨论获得的结果。换了一个模型并执行best subset selection and the lasso "><meta name="og:description" content="Sampling Methods and Model Selection8 Cross-Validation 生成数据集 设置随机种子，然后计算使用最小二乘拟合以下四个模型（增加次数的一次到四次的多项式）所产生的 LOOCV 误差 使用最小二乘法拟合以上的每个模型所产生的系数估计值的统计显着性。这些结果与基于交叉验证结果得出的结论一致吗？ 得出的结论X1和X2的t统计值的绝对值是最大的， 所以对应了二次项 9. 直接计算数据集的std 和mean 通过Bootstrap来估计数据集的std 和mean def boot(var, n): m = np.zeros(n) for i in range(0, n): v    = var.sample(frac=1, replace=True) 就是百分之百，采样，有放回 m[i] = np.mean(v) res1 = np.mean(m) res2 = np.std(m) print('mu: %.5f; se: %.5f' %(res1, res2)) return(res1, res2) 调用： result = boot(medv, 1000) # close to (b) 置信区间 print('lowerbd:%.2f' %(result[0] - 2*result[1])) print('upperbd:%.2f' %(result[0] + 2*result[1])) from scipy import statsstats.t.interval(0.95,               # confidence level df = len(df)-1, # degrees of freedom loc = mu_hat,       # sample mean scale= mu_hat_se)   # sample std dev 中位数 中位数的标准误差 rovide an estimate for the tenth percentile of y # 6.9 生成模拟数据集np.random.randn(1) 是用来生成一个标准正态分布的随机数的。np.random.randn() 函数生成一个随机数，该随机数服从标准正态分布（均值为0，标准差为1） （1）10* 100 个 X， y是一个多项式 (2) 放到一个数据框里 执行这个两种model selection(1)best subset selectionlm = OLS(fit_intercept=True) lm_exhaustive = exhaustive_search(lm, X_new_df, y,nvmax=len(X_new_df.columns)) (2)forward and backwardlm = OLS(fit_intercept=True)lm_forward = forward_search(lm, X_new_df, y, nvmax=len(X_new_df.columns))lm = OLS(fit_intercept=True)lm_backward = backward_search(lm, X_new_df, y, nvmin=1) 现在将==套索模型==拟合到模拟数据，再次使用 X,X2,…,X10 作为预测变量。==使用交叉验证来选择 λ 的最佳值==。(这个其实是一整步，它是一起的)创建作为 ==λ 函数的交叉验证误差图==。（连这个是跟之前那一步一起的）报告所得的==系数估计值==，并讨论获得的结果。==(同时要scale 数据)== scale scaler = StandardScaler() X_new = scaler.fit_transform(X_new) 2. lambdas = 10 ** np.linspace(3,-3,50)生成1000到0.001的50个等间距的值 mean_scores = np.zeros(len(lambdas)) std_scores = np.zeros(len(lambdas)) for i, lambda_ in enumerate(lambdas): 它用于计算模型在交叉验证中的得分（我scoring设置什么它算什么，cv.mean就得到它的mean） cv = cross_val_score(Lasso(lambda_, max_iter=10000),X_new, y, cv=10, scoring='neg_mean_squared_error') mean_scores[i] = cv.mean() std_scores[i] = cv.std() 3.![[d26871bc8cfbf8b45cc98feed382a87.png]]就是yerr是标准差，lecture也提到了，以标准差作为一个间距 找个mean_scroe最小的一点mn，和对应的lambdas就是opt ![[1e233ecedc7b7977808dd41ae0a9776.png]]这个结果就是，coefficient 为0 的变量就不被考虑了4.现在根据模型 y=β0+β7X7+e 生成响应向量 y ，并执行最佳子集选择和套索。讨论获得的结果。换了一个模型并执行best subset selection and the lasso "><meta property="og:url" content="https://buliangzhang24.github.io/2024/02/25/MachineLearning-W2L1,-L2/"><meta property="og:site_name" content="Xinyi He"><meta property="og:type" content="article"><meta property="og:locale" content="zh_CN" /><meta property="article:published_time" content="2024-02-25"> <script src="https://buliangzhang24.github.io/assets/vendor/jquery/dist/jquery.min.js"></script> <script src="https://buliangzhang24.github.io/assets/js/main.js"></script></head><body class="" data-mz=""><header class="site-header"><div class="container"><h1><a href="https://buliangzhang24.github.io/" title="Xinyi He"><span class="octicon octicon-mark-github"></span> Xinyi He</a></h1><button class="collapsed mobile-visible" type="button" onclick="toggleMenu();"> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button><nav class="site-header-nav" role="navigation"> <a href="https://buliangzhang24.github.io/" class="site-header-nav-item" target="" title="Home">Home</a> <a href="https://buliangzhang24.github.io/categories/" class="site-header-nav-item" target="" title="Categories">Categories</a> <a href="https://buliangzhang24.github.io/archives/" class="mobile-hidden site-header-nav-item" target="" title="Archives">Archives</a> <a href="https://buliangzhang24.github.io/fragments/" class="site-header-nav-item" target="" title="Fragments">Fragments</a> <a href="https://buliangzhang24.github.io/wiki/" class="site-header-nav-item" target="" title="Projects">Projects</a> <a href="https://buliangzhang24.github.io/links/" class="mobile-hidden site-header-nav-item" target="" title="Useful Links">Useful Links</a> <a href="https://buliangzhang24.github.io/about/" class="site-header-nav-item" target="" title="About">About</a> <a class="mobile-hidden" href="https://buliangzhang24.github.io/feed.xml"><span class="octicon octicon-rss" style="color:orange;"></span></a></nav></div></header><section class="collection-head small geopattern" data-pattern-id="MachineLearning"><div class="container"><div class="columns"><div class="column three-fourths"><div class="collection-title"><h1 class="collection-header">MachineLearning｜ Notes1</h1><div class="collection-info"> <span class="meta-info"> <span class="octicon octicon-calendar"></span> 2024/02/25 </span> <span class="meta-info"> <span class="octicon octicon-file-directory"></span> <a href="https://buliangzhang24.github.io/categories/#MachineLearning" title="MachineLearning">MachineLearning</a> </span> <span class="meta-info"> <span class="octicon octicon-clock"></span> 共 3572 字，约 11 分钟 </span></div></div></div><div class="column one-fourth mobile-hidden"><div class="collection-title"> <img style="height:72px;width:72px" src="https://buliangzhang24.github.io/assets/images/qrcode.jpg" alt="Buliangzhang" /></div></div></div></div></section><section class="container content"><div class="columns"><div class="column three-fourths" ><article class="article-content markdown-body"><h1 id="sampling-methods-and-model-selection">Sampling Methods and Model Selection</h1><h1 id="8-cross-validation">8 Cross-Validation</h1><ol><li>生成数据集</li><li>设置随机种子，然后计算使用最小二乘拟合以下四个模型（增加次数的一次到四次的多项式）所产生的 LOOCV 误差 <img src="https://buliangzhang24.github.io/images/posts/8a12a3b6920d745aa3dc8c5ac9d91b2.png" alt="" /></li><li>使用最小二乘法拟合以上的每个模型所产生的系数估计值的统计显着性。这些结果与基于交叉验证结果得出的结论一致吗？ <img src="https://buliangzhang24.github.io/images/posts/0d0d451665de7e96251ac828dfe981c.png" alt="" /> 得出的结论X1和X2的t统计值的绝对值是最大的， 所以对应了二次项<h1 id="9">9.</h1></li><li>直接计算数据集的std 和mean</li><li>通过Bootstrap来估计数据集的std 和mean <code class="language-plaintext highlighter-rouge">def boot(var, n):</code> <code class="language-plaintext highlighter-rouge">m = np.zeros(n)</code> <code class="language-plaintext highlighter-rouge">for i in range(0, n):</code> <code class="language-plaintext highlighter-rouge">v    = var.sample(frac=1, replace=True)</code> 就是百分之百，采样，有放回 <code class="language-plaintext highlighter-rouge">m[i] = np.mean(v)</code> <code class="language-plaintext highlighter-rouge">res1 = np.mean(m)</code> <code class="language-plaintext highlighter-rouge">res2 = np.std(m)</code> <code class="language-plaintext highlighter-rouge">print('mu: %.5f; se: %.5f' %(res1, res2))</code> <code class="language-plaintext highlighter-rouge">return(res1, res2)</code> 调用： <code class="language-plaintext highlighter-rouge">result = boot(medv, 1000) # close to (b)</code></li><li>置信区间<ol><li><code class="language-plaintext highlighter-rouge">print('lowerbd:%.2f' %(result[0] - 2*result[1]))</code> <code class="language-plaintext highlighter-rouge">print('upperbd:%.2f' %(result[0] + 2*result[1]))</code></li><li><code class="language-plaintext highlighter-rouge">from scipy import stats</code> <code class="language-plaintext highlighter-rouge">stats.t.interval(0.95,               # confidence level</code>  <code class="language-plaintext highlighter-rouge">df = len(df)-1, # degrees of freedom</code>  <code class="language-plaintext highlighter-rouge">loc = mu_hat,       # sample mean</code>  <code class="language-plaintext highlighter-rouge">scale= mu_hat_se)   # sample std dev</code></li></ol></li><li>中位数</li><li>中位数的标准误差</li><li>rovide an estimate for the tenth percentile of y # 6.9</li><li>生成模拟数据集 <code class="language-plaintext highlighter-rouge">np.random.randn(1)</code> 是用来生成一个标准正态分布的随机数的。<code class="language-plaintext highlighter-rouge">np.random.randn()</code> 函数生成一个随机数，该随机数服从标准正态分布（均值为0，标准差为1） （1）10* 100 个 X， y是一个多项式 (2) 放到一个数据框里</li><li>执行这个两种model selection (1)best subset selection <code class="language-plaintext highlighter-rouge">lm = OLS(fit_intercept=True)</code> <code class="language-plaintext highlighter-rouge">lm_exhaustive = exhaustive_search(lm, X_new_df, y,nvmax=len(X_new_df.columns))</code> (2)forward and backward <code class="language-plaintext highlighter-rouge">lm = OLS(fit_intercept=True)</code> <code class="language-plaintext highlighter-rouge">lm_forward = forward_search(lm, X_new_df, y, nvmax=len(X_new_df.columns))</code> <code class="language-plaintext highlighter-rouge">lm = OLS(fit_intercept=True)</code> <code class="language-plaintext highlighter-rouge">lm_backward = backward_search(lm, X_new_df, y, nvmin=1)</code></li><li>现在将==套索模型==拟合到模拟数据，再次使用 X,X2,…,X10 作为预测变量。==使用交叉验证来选择 λ 的最佳值==。(这个其实是一整步，它是一起的)创建作为 ==λ 函数的交叉验证误差图==。（连这个是跟之前那一步一起的）报告所得的==系数估计值==，并讨论获得的结果。==(同时要scale 数据)==<ol><li>scale scaler = StandardScaler() X_new = scaler.fit_transform(X_new) 2. <code class="language-plaintext highlighter-rouge">lambdas = 10 ** np.linspace(3,-3,50)</code>生成1000到0.001的50个等间距的值 <code class="language-plaintext highlighter-rouge">mean_scores = np.zeros(len(lambdas))</code> <code class="language-plaintext highlighter-rouge">std_scores = np.zeros(len(lambdas))</code> <code class="language-plaintext highlighter-rouge">for i, lambda_ in enumerate(lambdas):</code> 它用于计算模型在交叉验证中的得分（我scoring设置什么它算什么，cv.mean就得到它的mean） <code class="language-plaintext highlighter-rouge">cv = cross_val_score(Lasso(lambda_, max_iter=10000),X_new, y, cv=10, scoring='neg_mean_squared_error')</code> <code class="language-plaintext highlighter-rouge">mean_scores[i] = cv.mean()</code> <code class="language-plaintext highlighter-rouge">std_scores[i] = cv.std()</code> 3.![[d26871bc8cfbf8b45cc98feed382a87.png]]就是yerr是标准差，lecture也提到了，以标准差作为一个间距 找个mean_scroe最小的一点mn，和对应的lambdas就是opt ![[1e233ecedc7b7977808dd41ae0a9776.png]]这个结果就是，coefficient 为0 的变量就不被考虑了 4.现在根据模型 y=β0+β7X7+e 生成响应向量 y ，并执行最佳子集选择和套索。讨论获得的结果。换了一个模型并执行best subset selection and the lasso</li></ol></li></ol><p><code class="language-plaintext highlighter-rouge">lm_exhaustive.plot()</code>从这些图（RSS，AIC,BIC, R^2 , R^2 adjusted）从看出最佳的变量选择数量是多少，并用以下的代码来展现。 <code class="language-plaintext highlighter-rouge">print("AIC:", lm_exhaustive.get_model(n=3))</code> <code class="language-plaintext highlighter-rouge">print("BIC:", lm_exhaustive.get_model(n=1))</code> <code class="language-plaintext highlighter-rouge">print("R2_adj:", lm_exhaustive.get_model(n=5))</code></p><h1 id="610">6.10</h1><p>我只是简单地生成 X 和系数的正态分布值 - 这当然可以通过更奇特的方式来完成。我选择将 13 个系数设置为非零值</p><ul><li>分割train 和test <code class="language-plaintext highlighter-rouge">np.random.seed(42)</code> <code class="language-plaintext highlighter-rouge">mask = np.random.rand(len(X_df)) &lt; 0.9</code> <code class="language-plaintext highlighter-rouge">train = X_df[mask]</code> <code class="language-plaintext highlighter-rouge">test = X_df[~mask]</code> <code class="language-plaintext highlighter-rouge">print(mask.shape, train.shape, test.shape)</code> <code class="language-plaintext highlighter-rouge">X_train = train.drop('y', axis=1)</code> <code class="language-plaintext highlighter-rouge">y_train = train['y']</code> <code class="language-plaintext highlighter-rouge">X_test = test.drop('y', axis=1)</code> <code class="language-plaintext highlighter-rouge">y_test = test['y']</code> 或者 <code class="language-plaintext highlighter-rouge">X_train, X_test, y_train, y_test = train_test_split(X_df, y, test_size=0.9, random_state=13)</code><ol><li>生成新的数据集，但是常数给它是个矩阵，同时有一些元素赋值为0，加上执行scale</li><li>分割train和test</li><li>对训练集执行最佳子集选择，plot the training /test set MSE associated with the best model of each size.(这个size指的是特征数，就是自变量的个数) ![[5c1e5e26c06f762a38ba0fd0f4827fc.png]] 这个代码里面，.subset是求这个特定的模型对应的特征值有几个，在做Predict的时候，用到X_train和这个subset 就是这个代码<code class="language-plaintext highlighter-rouge">y_pred_trn = model.predict(X_train, subset)</code></li><li>10e For which model size does the test set MSE take on its minimum value? Comment on your results. If it takes on its minimum value for a model containing only an intercept or a model containing all of the features, then play around with the way that you are generating the data in 10a until you come up with a scenario in which the test set MSE is minimized for an intermediate model size. 对于哪个模型大小，测试集 MSE 取最小值？评论你的结果。如果它对于仅包含截距的模型或包含所有特征的模型呈现最小值，则尝试在 10a 中生成数据的方式，直到您提出一个场景，其中测试集 MSE对于中间模型尺寸被最小化。 <code class="language-plaintext highlighter-rouge">print("Minimum test set MSE = {} at {} features".format(np.min(tst_errors), np.argmin(tst_errors)+1))</code></li><li><mark class="hltr-red">测试集 MSE 最小化的模型与用于生成数据的真实模型相比如何？对系数值进行评论???</mark></li><li>创建一个图，显示 r 值范围的 ∑pj=1(βj−β^rj)2−−−−−−−−−−−−√ ，其中 βrj 是最佳模型的第 j 系数估计值包含 r 系数。评论你所观察到的事情。这与 的测试 MSE 图相比如何？ <img src="https://buliangzhang24.github.io/images/posts/617ccab94fb32d28a5da45066d0bc40.png" alt="" /></li></ol></li></ul><div style="margin-top:2em;padding:0 1.5em;border:1px solid #d3d3d3;background-color:#deebf7"><h3>文档信息</h3><ul><li>本文作者：<a href="https://buliangzhang24.github.io" target="_blank">Xinyi He</a></li><li>本文链接：<a href="https://buliangzhang24.github.io/2024/02/25/MachineLearning-W2L1,-L2/" target="_blank">https://buliangzhang24.github.io/2024/02/25/MachineLearning-W2L1,-L2/</a></li><li>版权声明：自由转载-非商用-非衍生-保持署名（<a href="http://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank">创意共享3.0许可证</a>）</li></ul></div></article><div class="share"></div><div class="comment"> <script src="https://giscus.app/client.js" data-repo="Buliangzhang24/Buliangzhang24.github.io" data-repo-id="MDEwOlJlcG9zaXRvcnk5MzEyNzkxNw==" data-category="Announcements" data-category-id="DIC_kwDOBY0E7c4CRtg9" data-mapping="title" data-strict="1" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="zh-CN" data-loading="lazy" crossorigin="anonymous" async> </script></div></div><div class="column one-fourth"><h3>Search</h3><div id="site_search"> <input style="width:96%" type="text" id="search_box" placeholder="Search"></div><ul id="search_results" style="font-size:14px;list-style-type:none;padding-top:10px;padding-left:10px;"></ul><script src="https://buliangzhang24.github.io/assets/js/simple-jekyll-search.min.js"></script> <script type="text/javascript"> SimpleJekyllSearch({ searchInput: document.getElementById('search_box'), resultsContainer: document.getElementById('search_results'), json: 'https://buliangzhang24.github.io/assets/search_data.json?v=1727808819', searchResultTemplate: '<li><a href="{url}" title="{title}">{title}</a></li>', noResultsText: 'No results found', limit: 10, fuzzy: false, exclude: ['Welcome'] }) </script><h3 class="post-directory-title mobile-hidden">Table of Contents</h3><div id="post-directory-module" class="mobile-hidden"><section class="post-directory"><dl></dl></section></div><script src="https://buliangzhang24.github.io/assets/js/jquery.toc.js"></script></div></div></section><footer class="container"><div class="site-footer" role="contentinfo"><div class="copyright left mobile-block"> © 2024 <span title="Xinyi He">Xinyi He</span> <a href="javascript:window.scrollTo(0,0)" class="right mobile-visible">TOP</a></div><ul class="site-footer-links right mobile-hidden"><li> <a href="javascript:window.scrollTo(0,0)" >TOP</a></li></ul><a href="https://github.com/Buliangzhang24/Buliangzhang24.github.io" target="_blank" aria-label="view source code"> <span class="mega-octicon octicon-mark-github" title="GitHub"></span> </a><ul class="site-footer-links mobile-hidden"><li> <a href="https://buliangzhang24.github.io/" title="Home" target="">Home</a></li><li> <a href="https://buliangzhang24.github.io/categories/" title="Categories" target="">Categories</a></li><li> <a href="https://buliangzhang24.github.io/archives/" title="Archives" target="">Archives</a></li><li> <a href="https://buliangzhang24.github.io/fragments/" title="Fragments" target="">Fragments</a></li><li> <a href="https://buliangzhang24.github.io/wiki/" title="Projects" target="">Projects</a></li><li> <a href="https://buliangzhang24.github.io/links/" title="Useful Links" target="">Useful Links</a></li><li> <a href="https://buliangzhang24.github.io/about/" title="About" target="">About</a></li><li><a href="https://buliangzhang24.github.io/feed.xml"><span class="octicon octicon-rss" style="color:orange;"></span></a></li></ul></div></footer><div class="tools-wrapper"> <a class="gotop" href="#" title="回到顶部"><span class="octicon octicon-arrow-up"></span></a></div><script src="https://buliangzhang24.github.io/assets/js/geopattern.js"></script> <script> jQuery(document).ready(function($) { $('.geopattern').each(function(){ $(this).geopattern($(this).data('pattern-id')); }); /* hljs.initHighlightingOnLoad(); */ }); </script></body></html>
