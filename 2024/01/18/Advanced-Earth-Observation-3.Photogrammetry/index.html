<!DOCTYPE html><html lang="zh-cmn-Hans" prefix="og: http://ogp.me/ns#" class="han-init"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" /><title>Advanced Earth Observation｜3.Photogrammetry &mdash; Xinyi He</title><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/vendor/primer-css/css/primer.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/components/collection.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/components/repo-card.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/sections/repo-list.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/components/boxed-group.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/globals/common.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/globals/responsive.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/css/posts/index.css"><link rel="stylesheet" href="https://buliangzhang24.github.io/assets/vendor/octicons/octicons/octicons.css"><link rel="stylesheet" href="https://mazhuang.org/rouge-themes/dist/github.css"><link rel="canonical" href="https://buliangzhang24.github.io/2024/01/18/Advanced-Earth-Observation-3.Photogrammetry/"><link rel="alternate" type="application/atom+xml" title="Xinyi He" href="https://buliangzhang24.github.io/feed.xml"><link rel="shortcut icon" href="https://buliangzhang24.github.io/favicon.ico"><meta property="og:title" content="Advanced Earth Observation｜3.Photogrammetry"><meta name="keywords" content="Photogrammetry"><meta name="og:keywords" content="Photogrammetry"><meta name="description" content="Exercise一. SfM photogrammetry of UAV data in Agisoft Metashape1. Import photos为什么不用起飞和降落时候的照片？The photos from take off and landing have already been removed, so all photos are at the same height level. ==However, the lines are not really parallel, but they are a bit skewed==. Dependent on the field of view of the camera this may cause issues with the overlap and with having enough different viewing angles over the entire scene.2. Project with UTM projectionGeographic data is often presented in a projected coordinate system, in order to visualize 3D data in two dimensions (on your screen). In this process longitude/latitude is converted to (x,y) coordinates."><meta name="og:description" content="Exercise一. SfM photogrammetry of UAV data in Agisoft Metashape1. Import photos为什么不用起飞和降落时候的照片？The photos from take off and landing have already been removed, so all photos are at the same height level. ==However, the lines are not really parallel, but they are a bit skewed==. Dependent on the field of view of the camera this may cause issues with the overlap and with having enough different viewing angles over the entire scene.2. Project with UTM projectionGeographic data is often presented in a projected coordinate system, in order to visualize 3D data in two dimensions (on your screen). In this process longitude/latitude is converted to (x,y) coordinates."><meta property="og:url" content="https://buliangzhang24.github.io/2024/01/18/Advanced-Earth-Observation-3.Photogrammetry/"><meta property="og:site_name" content="Xinyi He"><meta property="og:type" content="article"><meta property="og:locale" content="zh_CN" /><meta property="article:published_time" content="2024-01-18"> <script src="https://buliangzhang24.github.io/assets/vendor/jquery/dist/jquery.min.js"></script> <script src="https://buliangzhang24.github.io/assets/js/main.js"></script></head><body class="" data-mz=""><header class="site-header"><div class="container"><h1><a href="https://buliangzhang24.github.io/" title="Xinyi He"><span class="octicon octicon-mark-github"></span> Xinyi He</a></h1><button class="collapsed mobile-visible" type="button" onclick="toggleMenu();"> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button><nav class="site-header-nav" role="navigation"> <a href="https://buliangzhang24.github.io/" class="site-header-nav-item" target="" title="Home">Home</a> <a href="https://buliangzhang24.github.io/categories/" class="site-header-nav-item" target="" title="Categories">Categories</a> <a href="https://buliangzhang24.github.io/archives/" class="mobile-hidden site-header-nav-item" target="" title="Archives">Archives</a> <a href="https://buliangzhang24.github.io/fragments/" class="site-header-nav-item" target="" title="Fragments">Fragments</a> <a href="https://buliangzhang24.github.io/wiki/" class="site-header-nav-item" target="" title="Projects">Projects</a> <a href="https://buliangzhang24.github.io/links/" class="mobile-hidden site-header-nav-item" target="" title="Useful Links">Useful Links</a> <a href="https://buliangzhang24.github.io/about/" class="site-header-nav-item" target="" title="About">About</a> <a class="mobile-hidden" href="https://buliangzhang24.github.io/feed.xml"><span class="octicon octicon-rss" style="color:orange;"></span></a></nav></div></header><section class="collection-head small geopattern" data-pattern-id="Advanced Earth "><div class="container"><div class="columns"><div class="column three-fourths"><div class="collection-title"><h1 class="collection-header">Advanced Earth Observation｜3.Photogrammetry</h1><div class="collection-info"> <span class="meta-info"> <span class="octicon octicon-calendar"></span> 2024/01/18 </span> <span class="meta-info"> <span class="octicon octicon-file-directory"></span> <a href="https://buliangzhang24.github.io/categories/#Advanced Earth Observation" title="Advanced Earth Observation">Advanced Earth Observation</a> </span> <span class="meta-info"> <span class="octicon octicon-clock"></span> 共 9769 字，约 28 分钟 </span></div></div></div><div class="column one-fourth mobile-hidden"><div class="collection-title"></div></div></div></div></section><section class="container content"><div class="columns"><div class="column three-fourths" ><article class="article-content markdown-body"><h1 id="exercise">Exercise</h1><h2 id="一-sfm-photogrammetry-of-uav-data-in-agisoft-metashape">一. SfM photogrammetry of UAV data in Agisoft Metashape</h2><h3 id="1-import-photos">1. Import photos</h3><h4 id="为什么不用起飞和降落时候的照片">为什么不用起飞和降落时候的照片？</h4><p>The photos from take off and landing have already been removed, so all photos are at the same height level. ==However, the lines are not really parallel, but they are a bit skewed==. Dependent on the field of view of the camera this may cause issues with the overlap and with having enough different viewing angles over the entire scene.</p><h3 id="2-project-with-utm-projection">2. Project with UTM projection</h3><p>Geographic data is often presented in a projected coordinate system, in order to visualize 3D data in two dimensions (on your screen). In this process longitude/latitude is converted to (x,y) coordinates.</p><p>Every projection comes with distortions and some projections tend to preserve angle (conformal projections), area (equal-area projections) or distance (equidistant projections). Not a single projection can preserve all three properties. The Universal Transverse Mercator (UTM) projection averages the degree of distortion over all three properties.</p><h3 id="3-import-ground-control-points">3. Import ground control points</h3><h3 id="4-camera-alignment">4. Camera Alignment</h3><h4 id="which-processing-steps-of-camera-alignment">Which processing steps of camera alignment</h4><ul><li>point detection</li><li>matching points</li><li>estimating camera locations</li><li>adjusting camera locations For each picture the software identifies objects, these points are used to match the neighbouring pictures, it selects the identifiable pairs between the neighbouring images and aligns them.<h4 id="metashape-align-all-images-is-this-a-sequential-process">Metashape align all images is this a sequential process</h4><p>Each time photos are added, which are aligned to the already registered photos</p><h3 id="5-mark-ground-control-points">5. Mark ground control points</h3><h4 id="show-point-residuals">Show point residuals</h4><p>there are points which are identified in multiple images and which are thus used as tie-points. (The blue points are used points, used for creating the camera alignment, which also overlapping features of each pair. The grey points are not used for creating the camera alignment.)</p></li></ul><p>However, no all points are shown (at least not ~2000 of them per photo), so they don’t always show up at the same location. Actually that is a bit a vague implementation.</p><h4 id="照片没有aligned的原因和解决方法">照片没有aligned的原因和解决方法</h4><p>If some of the photos are not properly aligned there may be too little overlap, or a lack of identifiable features. Changing the quality settings to a higher level may change the number of aligned images, as well as the preselection settings.</p><h3 id="6-build-dense-cloud">6. Build Dense Cloud</h3><h3 id="7-build-mesh">7. Build mesh</h3><p>The other settings include</p><ul><li>tie points and point cloud for source data</li><li>arbitrary (3D)</li><li>height field (2.5D) For a 3D reconstruction you would go for ==arbitrary==, which also allows you to create a mesh on the sides of objects. Also for trees this is the best method. For orthophoto information on the depth is needed and not about the sides of the object, ==height field,== which makes the setting height field sufficient.<h3 id="8-build-texture">8. Build Texture</h3><h5 id="what-can-you-say-about-the-age-of-the-landslide-activation-is-this-a-very-recent-landslide-or-do-you-think-it-is-already-old">What can you say about the age of the landslide activation? Is this a very recent landslide or do you think it is already “old”?</h5><p>The edges are quite ==steep== so this is a fairly recent landslide. If it would have been older the edges would have been less sharp. Also some plant rows are crossing the drainage gullies沟, although not in a straight line</p><h5 id="management-to-improve-the-stability-of-the-slope">management to improve the stability of the slope</h5><p>Ploughing parallel to the slope, creating terraces</p><h2 id="二-surface-reconstruction-of-a-mixed-area-with-different-cameras">二. Surface reconstruction of a mixed area with different cameras</h2><h3 id="p1和x7相机">P1和X7相机</h3><p>P1 camera captured more details of the canopies of the trees, compared to X7 that is missing points there. The main difference in the amount of detail between the cameras lies in the capacity of the lens and the GPS system of the device.</p></li></ul><p>All photo’s will be aligned and the pointcloud makes sense. There is enough overlap, so there should be no big issues. Visually you’ll see that it is definitely harder to reconstruct the trees. The pavement, containers, grass etc will look good, but especially the tree crowns will show quite some gaps.</p><h4 id="explain-the-difference-between-the-different-cameras">Explain the difference between the different camera’s.</h4><p>the P1 camera is a pretty good camera, so it can autodetect most of the GCP’s and their codes automatically.</p><p>The initial error for the X7 camera will be around 60-70 cm, while for the P1 this is much lower. The use of RTK on the drone is really helpful here, since the starting locations of the pictures are much more accurate (which we could use as a constraint in the model). Personally, I wouldn’t use the X7 without GCP’s when I’m aiming for a very high accuracy, while the P1 in combination with RTK comes pretty close.</p><h3 id="dense-cloud-confidence">Dense Cloud Confidence</h3><p>The confidence for points on the ground (road) and tops of the emergent trees is highest. These are also the areas which are most stable (==no wind==) or properly covered by multiple images. The areas with lower confidence are probably covered by less photos, lowering the programs confidence indicator.</p><h3 id="profile-tool">profile tool</h3><p>Only when the ground surface is directly visible, but you will have no points on the ground when you are looking at e.g. the maize on the west, trees in the middle, or elephant grass on the east side of the area.</p><p>Photogrammetry relies on objects which you can see from ==different directions== with enough contrast to distinguish features</p><h3 id="sfm-create-dsm">SfM create DSM</h3><p>(SfM technique as a whole the capabilities of this method to create a DEM of a partially vegetated?) 不能 You will not be able to see what is underneath the vegetation, for sure not from enough different observation angles, to reconstruct the surface. So instead of a DEM you do get a DSM, with all object like vegetation still in it. You would have to remove this and interpolate the terrain height.</p><h2 id="三generate-your-own-3d-model-and-evaluate-the-process">三.Generate your own 3D model and evaluate the process.</h2><h1 id="ppt">PPT</h1><h2 id="aerial-photography">Aerial Photography</h2><h3 id="benefits">Benefits</h3><p>Literally zoom-out, Overview of patterns in landscapes, Better understand context</p><h3 id="platforms">Platforms</h3><p>any flying object, including: Aircraft, Helicopter, Balloon, Kite, UAV</p><h2 id="photogrammetry">Photogrammetry</h2><p>Science of making reliable measurements by the use of photographs(size, shape, geographic positioning) Reconstructing the geometry of the photographed surface.</p><h2 id="parallax原理">Parallax»原理</h2><p>a displacement or difference in the apparent position of an object viewed along two different lines of sight, and is measured by the angle of inclination between those two lines. <img src="https://buliangzhang24.github.io/images/posts/b8e869d4d6711161d9eabb7af475080.png" alt="" /></p><h2 id="立体视觉overlapping-stereophotography">立体视觉»Overlapping Stereophotography</h2><h3 id="what">What</h3><ul><li>Overlapping photography is needed to determine parallax and stereo/3D viewing»&gt; Forward overlap - ~60% Side overlap - ~20-30%</li><li>Overlapping photos, image pairs»&gt;Same features from different angles in different photos, distorted in a different way<h3 id="基于">基于：</h3><p>Inner orientation</p></li><li>Known camera parameters</li><li>Position of feature in the photo(known degree of distortion) Exterior orientation</li><li>Position and orientation of the camera with respect to the object</li><li>Position and orientation of camera’s to each other<h2 id="aerial-photograph航拍图片的问题">Aerial Photograph航拍图片的问题</h2></li><li>Lens distortion– Distortions toward <strong>edge</strong> of picture</li><li>Camera tilt – Doesn’t always point straight down</li><li>Altitude variation during flight– <strong>Scale varies</strong> with elevation</li><li>Earth curvature(地球曲率)– scale 1:10000 – distance &gt; 10 km – dh = 60cm</li><li>Atmospheric distortion– when working at scale of &gt; 1:50000</li><li>Scale varies across photograph due to all previous– Parallax shift历史原因哈哈哈哈<h2 id="航拍和摄影测量结合">航拍和摄影测量结合</h2></li><li>Use <strong>overlap</strong> of aerial photos to view photos in stereo</li><li><strong>Correct</strong> photos for camera angle and altitude</li><li>==Parallax shift determines altitude==<h3 id="relief-displacement">Relief displacement</h3></li></ul><p><img src="https://buliangzhang24.github.io/images/posts/7b6d25d05c063b9c96a78dec680064d.png" alt="" /></p><h2 id="maps-vs-aerial-photos地图和航拍的比较">Maps vs. Aerial Photos地图和航拍的比较</h2><p>Nadir» direct</p><ul><li>Maps: Scale is constant»&gt;No relief displacement</li><li>Photos: Scale varies with tilts and elevation»&gt;Relief displacement</li><li>Orthophoto: aerial photograph with the geometry of a map »&gt;No relief displacement<h2 id="stereoscopic-parallax立体视差">Stereoscopic Parallax立体视差</h2></li><li>The ==displacement of an object== caused by a change in the point of observation is called parallax.</li><li>Caused by taking photographs of the same object but from ==different points of observation.== ![[43b2a5cd3b79686ec4c4837333aabd8.png]]<h3 id="absolute-stereoscopic-parallax">Absolute stereoscopic parallax</h3></li><li>PP = Principal point = nadir point of photo (hopefully center)</li><li>CPP = Conjugate principal point = adjacent photo’s PP</li><li>Absolute stereoscopic parallax → the average photo base length = average distance between PP and CPP → related to difference in scale of photos ![[de93a417193ecedbb3a46bdff0b2904.png]]</li></ul><h3 id="differential-parallax">Differential parallax</h3><p>Differential parallax - the difference between the stereoscopic parallax at the top and base of the object. ![[469a2cf4d339ae69a57a43de7d857be.png]]</p><h3 id="computing-height-using-stereoscopic-parallax">Computing height using stereoscopic parallax</h3><ul><li>If we know: Camera orientation, Orientation of the photo in the camera:</li><li>h = (H’) * dP / (P + dP) where h = object height, H’ = flying height, dP = differential parallax, P = average photo base length<h3 id="calculating-object-heights">Calculating Object Heights</h3></li><li>Object heights can be determined as follows: calculate flight altitude (H’) by multiplying the scale denominator by the focal length of the camera</li><li>==h = d * H’ / r ==where: h = Object height(要求的), d = length of object from base to top, r = distance from P.P. to top of object , H’= Flying Height above terrain ![[a1dd4a06465717c7d3bdd5d3946f2f2.png]]<h2 id="source-of-distortion扭曲的来源">Source of distortion扭曲的来源</h2><ol><li>Lens distortion</li><li>Camera orientation with respect to the object相机相对于物体</li><li>Camera distance with respect to the object相机相对于物体的距离用 Camera Calibration（相机标定）来修正<h2 id="structure-from-motionsfm-photogrammetry">Structure-from-Motion(SfM) photogrammetry</h2><h3 id="automated-surface-reconstruction">Automated surface reconstruction</h3></li></ol></li><li>Automated feature detection</li><li>Automated estimation of internal camera parameters (distortion)</li><li>Automated estimation of external camera parameters (position and orientation)</li><li>Automated 3D reconstruction of the object or landscape<h3 id="input">Input:</h3></li><li>Very large collection of photos with high degree of overlap</li><li>GPS information in EXIF metadata of imagery already geo references the surface reconstruction.<h3 id="output">Output</h3></li><li>3D point cloud</li><li>Mesh → Digital Surface Model网格</li><li>Texture → Orthorectified mosaic纹理<h3 id="sfm-objective-function">SfM Objective function:</h3><p>minimize reprojection error</p></li><li>旋转平移：Given point x and rotation and translation R, t</li><li>最小化SR：Minimize sum of squared reprojection errors g 但Minimizing g is difficult:</li><li>g is non-linear due to rotations, perspective division</li><li>lots of parameters: 3 for each 3D point, 6 for each camera</li><li>difficult to initialize Many techniques use non-linear least-squares (NLLS) optimization (bundle adjustment)用一些非线性技术高级一点<h3 id="sift-scale-invariant-feature-transform-detector-and-descriptor尺度不变特征变换">SIFT (Scale Invariant Feature Transform) Detector and Descriptor尺度不变特征变换</h3><p>Image content is transformed into local feature coordinates that are invariant to translation, rotation, scale, and other imaging parameters</p><h3 id="uses-for-siftfeature-points-are-used-also-for">(Uses for SIFT)Feature points are used also for:</h3></li><li>Image alignment (homography, fundamental matrix)</li><li>3D reconstruction (e.g. Photo Tourism)</li><li>Motion tracking</li><li>Object recognition</li><li>Indexing and database retrieval</li><li>Robot navigation<h1 id="sfm-photogrammetry-in-agisoft-metashape">SfM photogrammetry in Agisoft Metashape</h1></li></ul><h2 id="流程">流程：</h2><ul><li>Camera alignment</li><li>Identify manually measured ground targets»Accuracy ground control mark</li><li>Dense point cloud</li><li>Triangulate mesh</li><li>Blend texture on top of the mesh<h2 id="export-results">Export results</h2></li><li>3D point cloud</li><li>Digital Surface Model</li><li>Orthorectified mosaic -&gt; map geometry!!</li><li>Only then the “real” analysis starts<h2 id="requirements可能遇见的问题">Requirements可能遇见的问题</h2></li><li>Enough overlap (min 60%)</li><li>Enough photo’s (min 6)重叠</li><li>Distinctive features (many!)特征</li><li>Stable objects during acquisition稳定</li><li>Multiple camera positions多个相机位置<h2 id="accuracy">Accuracy</h2><h2 id="source-of-error--solution可能遇见的问题">Source of Error &amp; Solution可能遇见的问题</h2></li><li>Lens Distortions (or properties)»Calibrate camera</li><li>Positions Estimation (XYZ) » RTK GPS attached to camera and Use Ground control points and scale bars (for UAV measured with RTK)</li><li>Camera orientation (roll, pitch, yaw) IMU? But this is technically challenging…</li><li>Overlap Proper flight/image acquisition planning»Stable image features Some objects just don’t work…(e.g. water, moving objects)</li><li>Reconstructing very complex structures» Some objects just don’t work…(don’t expect miracles, they don’t happen in photogrammetry)</li></ul><div style="margin-top:2em;padding:0 1.5em;border:1px solid #d3d3d3;background-color:#deebf7"><h3>文档信息</h3><ul><li>本文作者：<a href="https://buliangzhang24.github.io" target="_blank">Xinyi He</a></li><li>本文链接：<a href="https://buliangzhang24.github.io/2024/01/18/Advanced-Earth-Observation-3.Photogrammetry/" target="_blank">https://buliangzhang24.github.io/2024/01/18/Advanced-Earth-Observation-3.Photogrammetry/</a></li><li>版权声明：自由转载-非商用-非衍生-保持署名（<a href="http://creativecommons.org/licenses/by-nc-nd/3.0/deed.zh" target="_blank">创意共享3.0许可证</a>）</li></ul></div></article><div class="share"></div><div class="comment"> <script src="https://giscus.app/client.js" data-repo="Buliangzhang24/Buliangzhang24.github.io" data-repo-id="MDEwOlJlcG9zaXRvcnk5MzEyNzkxNw==" data-category="Announcements" data-category-id="DIC_kwDOBY0E7c4CRtg9" data-mapping="title" data-strict="1" data-reactions-enabled="1" data-emit-metadata="0" data-input-position="top" data-theme="light" data-lang="zh-CN" data-loading="lazy" crossorigin="anonymous" async> </script></div></div><div class="column one-fourth"><h3>Search</h3><div id="site_search"> <input style="width:96%" type="text" id="search_box" placeholder="Search"></div><ul id="search_results" style="font-size:14px;list-style-type:none;padding-top:10px;padding-left:10px;"></ul><script src="https://buliangzhang24.github.io/assets/js/simple-jekyll-search.min.js"></script> <script type="text/javascript"> SimpleJekyllSearch({ searchInput: document.getElementById('search_box'), resultsContainer: document.getElementById('search_results'), json: 'https://buliangzhang24.github.io/assets/search_data.json?v=1727806130', searchResultTemplate: '<li><a href="{url}" title="{title}">{title}</a></li>', noResultsText: 'No results found', limit: 10, fuzzy: false, exclude: ['Welcome'] }) </script><h3 class="post-directory-title mobile-hidden">Table of Contents</h3><div id="post-directory-module" class="mobile-hidden"><section class="post-directory"><dl></dl></section></div><script src="https://buliangzhang24.github.io/assets/js/jquery.toc.js"></script></div></div></section><footer class="container"><div class="site-footer" role="contentinfo"><div class="copyright left mobile-block"> © 2024 <span title="Xinyi He">Xinyi He</span> <a href="javascript:window.scrollTo(0,0)" class="right mobile-visible">TOP</a></div><ul class="site-footer-links right mobile-hidden"><li> <a href="javascript:window.scrollTo(0,0)" >TOP</a></li></ul><a href="https://github.com/Buliangzhang24/Buliangzhang24.github.io" target="_blank" aria-label="view source code"> <span class="mega-octicon octicon-mark-github" title="GitHub"></span> </a><ul class="site-footer-links mobile-hidden"><li> <a href="https://buliangzhang24.github.io/" title="Home" target="">Home</a></li><li> <a href="https://buliangzhang24.github.io/categories/" title="Categories" target="">Categories</a></li><li> <a href="https://buliangzhang24.github.io/archives/" title="Archives" target="">Archives</a></li><li> <a href="https://buliangzhang24.github.io/fragments/" title="Fragments" target="">Fragments</a></li><li> <a href="https://buliangzhang24.github.io/wiki/" title="Projects" target="">Projects</a></li><li> <a href="https://buliangzhang24.github.io/links/" title="Useful Links" target="">Useful Links</a></li><li> <a href="https://buliangzhang24.github.io/about/" title="About" target="">About</a></li><li><a href="https://buliangzhang24.github.io/feed.xml"><span class="octicon octicon-rss" style="color:orange;"></span></a></li></ul></div></footer><div class="tools-wrapper"> <a class="gotop" href="#" title="回到顶部"><span class="octicon octicon-arrow-up"></span></a></div><script src="https://buliangzhang24.github.io/assets/js/geopattern.js"></script> <script> jQuery(document).ready(function($) { $('.geopattern').each(function(){ $(this).geopattern($(this).data('pattern-id')); }); /* hljs.initHighlightingOnLoad(); */ }); </script></body></html>
